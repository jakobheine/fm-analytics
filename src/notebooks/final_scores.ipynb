{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Workbook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install python dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "source": [
    "!pip install -q -r ./dependencies/requirements.txt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/home/jakob/dev/fm-analytics/src/notebooks/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load python libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from math import sqrt\n",
    "\n",
    "import researchpy as rp\n",
    "\n",
    "import autosklearn.regression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "source": [
    "df = pd.read_csv('./data/final_scores.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add prev_score coloumn\n",
    "\n",
    "Calculated after research in **smoothing_comparison.ipynb**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "source": [
    "df_prev_score = pd.DataFrame()\n",
    "\n",
    "for player, df_player in df.groupby(['name']):\n",
    "    \n",
    "    df_player = df_player.sort_values('matchday')\n",
    "    df_player.set_index('matchday')\n",
    "    df_player['prev_score'] = df_player.final_score.ewm(alpha=0.5, adjust=False).mean().map(lambda x: int(x)).shift(periods=1, fill_value=0)\n",
    "\n",
    "    df_prev_score = df_prev_score.append(df_player, ignore_index=True)\n",
    "\n",
    "df = df_prev_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Min-Max-Scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "source": [
    "scaled_columns = ['prev_score' , 'odds_win', 'odds_draw', 'odds_lose']\n",
    "df_scaled = pd.DataFrame(MinMaxScaler().fit_transform(df[scaled_columns]), columns=scaled_columns)\n",
    "df = df.drop(scaled_columns, axis='columns').join(df_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-Hot-Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "source": [
    "one_hot_columns = ['club_id', 'position']\n",
    "df = pd.get_dummies(data=df, columns=one_hot_columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate accuracies for different models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate price function for statistical test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "source": [
    "# Values from SPITCH\n",
    "df_price = pd.DataFrame()\n",
    "df_price['percentage_above_threshhold'] = [0.15,0.14,0.13,0.12,0.11,0.10,0.09,0.08,0.07,0.06,0.05,0.04,0.03,0.02,0.01]\n",
    "df_price['price_in_%'] = [15, 7, 4.5, 3.3, 2.6, 2.2, 1.8, 1.6, 1.4, 1.3,1.1,1.1,0.89,0.89,0.89]\n",
    "\n",
    "def exponenial_func(x, a, b, c):\n",
    "    return a*np.exp(-b*x)+c\n",
    "\n",
    "# Calculate best parameters p for exponential function \n",
    "popt, pcov = curve_fit(exponenial_func, df_price['percentage_above_threshhold'], df_price['price_in_%'])\n",
    "\n",
    "df_price['price_in_%_calc'] = exponenial_func(df_price['percentage_above_threshhold'], *popt)\n",
    "\n",
    "def calculate_price(threshhold, percentage, stake=2, participants=1000):\n",
    "    price = float(stake * -1)\n",
    "\n",
    "    percentage_above_threshhold = percentage - threshhold\n",
    "    percentage_above_threshhold = 0.15 if percentage_above_threshhold > 0.15 else percentage_above_threshhold\n",
    "\n",
    "    total_price = participants * stake\n",
    "    percentage_of_price = exponenial_func(percentage_above_threshhold, *popt) / 100\n",
    "\n",
    "    if percentage_above_threshhold >= 0:\n",
    "        price = (total_price * percentage_of_price) + price\n",
    "\n",
    "    return price\n",
    "\n",
    "calculate_price(0.75, 0.76)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23.92812087022581"
      ]
     },
     "metadata": {},
     "execution_count": 370
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load helper methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "source": [
    "def calculate_best_lineup(df, score_column):\n",
    "    possible_lineups = [[3,4,3], [3,5,2], [4,2,4], [4,3,3], [4,4,2], [4,5,1], [5,3,2], [5,4,1], [5,2,3], [3,3,4]]\n",
    "\n",
    "    best_lineup = pd.DataFrame({score_column: 0}, index=[0])\n",
    "\n",
    "    for number_of_defender, number_of_midfielder, number_of_attacker in possible_lineups:\n",
    "        df_goalkeeper = df.loc[df['position_goalkeeper'] == True].nlargest(1, score_column, keep='first')\n",
    "        df_defender = df.loc[df['position_defender'] == True].nlargest(number_of_defender, score_column, keep='first')\n",
    "        df_midfielder = df.loc[df['position_midfielder'] == True].nlargest(number_of_midfielder, score_column, keep='first')\n",
    "        df_attacker = df.loc[df['position_attacker'] == True].nlargest(number_of_attacker, score_column, keep='first')\n",
    "\n",
    "        df_lineup = pd.concat([df_goalkeeper, df_defender, df_midfielder, df_attacker])\n",
    "\n",
    "        captain_id = df_lineup['final_score'].idxmax()\n",
    "        captain_score = df_lineup.at[captain_id, 'final_score']\n",
    "        df_lineup.at[captain_id, 'final_score'] = captain_score * 2    \n",
    "\n",
    "        if df_lineup[score_column].sum() > best_lineup[score_column].sum():\n",
    "            best_lineup = df_lineup\n",
    "\n",
    "    return best_lineup\n",
    "\n",
    "def calculate_lineup_accuracies(df):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for matchday, df_matchday in df.groupby('matchday'):\n",
    "        df_predicted_lineup = calculate_best_lineup(df_matchday, 'predicted_score')\n",
    "        df_best_lineup = calculate_best_lineup(df_matchday, 'final_score')\n",
    "\n",
    "        predicted_lineup_total_score = df_predicted_lineup['final_score'].sum()\n",
    "        best_lineup_total_score = df_best_lineup['final_score'].sum()\n",
    "\n",
    "        df_results = df_results.append({'Matchday': matchday, 'Predicted': predicted_lineup_total_score, 'Best': best_lineup_total_score }, ignore_index=True)\n",
    "\n",
    "    df_results = df_results[['Matchday', 'Predicted', 'Best']]\n",
    "\n",
    "    df_results['Difference'] = df_results['Best'] - df_results['Predicted']\n",
    "    df_results['points_in_%'] = round(df_results['Predicted'] / df_results['Best'],2)\n",
    "\n",
    "    threshhold = 0.75\n",
    "\n",
    "    df_results['is_over_threshhold'] = df_results['points_in_%'] >= threshhold\n",
    "    df_results['price_money'] = df_results['points_in_%'].apply(lambda x: calculate_price(threshhold, x))\n",
    "\n",
    "    return {'MAE_Lineup': df_results['Difference'].mean(), 'Std_Lineup': df_results['Difference'].std(), 'Mean_%_from_Best_Lineup': df_results['points_in_%'].mean(), 'Std_%_from_Best_Lineup': df_results['points_in_%'].std(), 'percentages_from_best_lineup': df_results['points_in_%'], 'differences_from_best_lineup': df_results['Difference'], 'Price_Money': round(df_results['price_money'].sum(),2), 'Mean_Price_Money': round(df_results['price_money'].mean(),2), 'Std_Price_Money': round(df_results['price_money'].std(),2), 'Count_Price_Won': df_results['is_over_threshhold'].sum()}\n",
    "\n",
    "def calculate_regression_accuracies(y, yhat):\n",
    "    mae = metrics.mean_absolute_error(y, yhat)\n",
    "    mse = metrics.mean_squared_error(y, yhat)\n",
    "    rmse = np.sqrt(mse) \n",
    "    r2 = metrics.r2_score(y, yhat)\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "def get_models():\n",
    "    linr = LinearRegression() # linear regression model\n",
    "    logr = LogisticRegression() # logistic regression model\n",
    "    dt = DecisionTreeRegressor() # decision tree model\n",
    "    rf = RandomForestRegressor() # random forest model\n",
    "    rf_tuned = RandomForestRegressor(bootstrap=True, max_depth=10, max_features='sqrt', min_samples_leaf=5, min_samples_split=2, n_estimators=1635) # random forest model\n",
    "    kn = KNeighborsRegressor() # k-nearest neighbours model\n",
    "    sv = svm.SVC() # support vector machine model\n",
    "    return [linr, logr, dt, rf,rf_tuned, kn, sv]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "source": [
    "df_model_accuracies = pd.DataFrame() \n",
    "\n",
    "designs = ['treatment', 'baseline']\n",
    "models = get_models()\n",
    "\n",
    "for design in designs:\n",
    "    \n",
    "    # drop betting odds for baseline models\n",
    "    if design=='baseline':\n",
    "        odds_columns = ['odds_win', 'odds_draw', 'odds_lose']\n",
    "        df = df.drop(odds_columns, axis=1)\n",
    "\n",
    "    # split into train and test data set\n",
    "    df_train = df[df['matchday'] <= 28]\n",
    "    df_test = df[df['matchday'] > 28]\n",
    "\n",
    "    # drop irrelevant features\n",
    "    df_train = df_train.drop(['name', 'matchday'], axis=1)\n",
    "\n",
    "    # split test data into feature and label\n",
    "    X_train = df_train.drop(['final_score'], axis='columns')\n",
    "    y_train = df_train['final_score']\n",
    "\n",
    "    for model in tqdm(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        model_inputs = df_test.drop(['name', 'matchday', 'final_score'], axis=1)\n",
    "        predicted_scores = model.predict(model_inputs)\n",
    "\n",
    "        df_final = df_test.copy(deep=False)\n",
    "        df_final['predicted_score'] = predicted_scores\n",
    "\n",
    "        regression_accuracies = calculate_regression_accuracies(df_final['final_score'], df_final['predicted_score'])\n",
    "        lineup_accuracies = calculate_lineup_accuracies(df_final)\n",
    "\n",
    "        accuracies = {**regression_accuracies, **lineup_accuracies}\n",
    "        accuracies['model'] = model\n",
    "        accuracies['design'] = design\n",
    "\n",
    "        df_model_accuracies = df_model_accuracies.append(accuracies, ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7/7 [00:29<00:00,  4.23s/it]\n",
      "100%|██████████| 7/7 [00:26<00:00,  3.82s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare model accuracies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "source": [
    "df_model_accuracies[['design', 'model', 'Mean_%_from_Best_Lineup', 'Std_%_from_Best_Lineup', 'MAE_Lineup', 'Std_Lineup', 'MAE', 'R2', 'Price_Money', 'Mean_Price_Money', 'Std_Price_Money', 'Count_Price_Won']].sort_values('Mean_%_from_Best_Lineup', ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>design</th>\n",
       "      <th>model</th>\n",
       "      <th>Mean_%_from_Best_Lineup</th>\n",
       "      <th>Std_%_from_Best_Lineup</th>\n",
       "      <th>MAE_Lineup</th>\n",
       "      <th>Std_Lineup</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Price_Money</th>\n",
       "      <th>Mean_Price_Money</th>\n",
       "      <th>Std_Price_Money</th>\n",
       "      <th>Count_Price_Won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>treatment</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.108950</td>\n",
       "      <td>1483.666667</td>\n",
       "      <td>442.249100</td>\n",
       "      <td>72.594094</td>\n",
       "      <td>0.211413</td>\n",
       "      <td>40.45</td>\n",
       "      <td>6.74</td>\n",
       "      <td>13.54</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baseline</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.638333</td>\n",
       "      <td>0.081833</td>\n",
       "      <td>1671.666667</td>\n",
       "      <td>365.769691</td>\n",
       "      <td>73.115933</td>\n",
       "      <td>0.200557</td>\n",
       "      <td>13.96</td>\n",
       "      <td>2.33</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treatment</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=10, max_featu...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.120457</td>\n",
       "      <td>1743.000000</td>\n",
       "      <td>602.137526</td>\n",
       "      <td>71.819449</td>\n",
       "      <td>0.216850</td>\n",
       "      <td>13.96</td>\n",
       "      <td>2.33</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>treatment</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.087958</td>\n",
       "      <td>1830.666667</td>\n",
       "      <td>509.688009</td>\n",
       "      <td>73.820577</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>baseline</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=10, max_featu...</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.065243</td>\n",
       "      <td>1913.833333</td>\n",
       "      <td>361.920663</td>\n",
       "      <td>72.173631</td>\n",
       "      <td>0.204637</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>treatment</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.099933</td>\n",
       "      <td>2034.500000</td>\n",
       "      <td>563.912671</td>\n",
       "      <td>99.665262</td>\n",
       "      <td>-0.519691</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>baseline</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.074744</td>\n",
       "      <td>2044.166667</td>\n",
       "      <td>458.073538</td>\n",
       "      <td>80.895114</td>\n",
       "      <td>0.015363</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>treatment</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.077136</td>\n",
       "      <td>2070.833333</td>\n",
       "      <td>417.719244</td>\n",
       "      <td>79.589731</td>\n",
       "      <td>0.048406</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>baseline</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.117757</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>527.585822</td>\n",
       "      <td>89.476773</td>\n",
       "      <td>-0.260619</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>baseline</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.080166</td>\n",
       "      <td>2109.666667</td>\n",
       "      <td>373.172704</td>\n",
       "      <td>78.254279</td>\n",
       "      <td>0.058488</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>treatment</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.096678</td>\n",
       "      <td>2137.833333</td>\n",
       "      <td>403.852655</td>\n",
       "      <td>89.734311</td>\n",
       "      <td>-0.253249</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>baseline</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>2227.333333</td>\n",
       "      <td>542.415216</td>\n",
       "      <td>100.990465</td>\n",
       "      <td>-0.537225</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>treatment</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.042622</td>\n",
       "      <td>2365.666667</td>\n",
       "      <td>268.500776</td>\n",
       "      <td>84.979625</td>\n",
       "      <td>-0.114571</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baseline</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.106724</td>\n",
       "      <td>2487.666667</td>\n",
       "      <td>563.395657</td>\n",
       "      <td>84.419723</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       design                                              model  \\\n",
       "0   treatment                                 LinearRegression()   \n",
       "7    baseline                                 LinearRegression()   \n",
       "4   treatment  (DecisionTreeRegressor(max_depth=10, max_featu...   \n",
       "3   treatment  (DecisionTreeRegressor(max_features='auto', ra...   \n",
       "11   baseline  (DecisionTreeRegressor(max_depth=10, max_featu...   \n",
       "2   treatment                            DecisionTreeRegressor()   \n",
       "10   baseline  (DecisionTreeRegressor(max_features='auto', ra...   \n",
       "5   treatment                              KNeighborsRegressor()   \n",
       "8    baseline                               LogisticRegression()   \n",
       "12   baseline                              KNeighborsRegressor()   \n",
       "1   treatment                               LogisticRegression()   \n",
       "9    baseline                            DecisionTreeRegressor()   \n",
       "6   treatment                                              SVC()   \n",
       "13   baseline                                              SVC()   \n",
       "\n",
       "    Mean_%_from_Best_Lineup  Std_%_from_Best_Lineup   MAE_Lineup  Std_Lineup  \\\n",
       "0                  0.675000                0.108950  1483.666667  442.249100   \n",
       "7                  0.638333                0.081833  1671.666667  365.769691   \n",
       "4                  0.625000                0.120457  1743.000000  602.137526   \n",
       "3                  0.608333                0.087958  1830.666667  509.688009   \n",
       "11                 0.588333                0.065243  1913.833333  361.920663   \n",
       "2                  0.563333                0.099933  2034.500000  563.912671   \n",
       "10                 0.563333                0.074744  2044.166667  458.073538   \n",
       "5                  0.555000                0.077136  2070.833333  417.719244   \n",
       "8                  0.553333                0.117757  2063.000000  527.585822   \n",
       "12                 0.543333                0.080166  2109.666667  373.172704   \n",
       "1                  0.536667                0.096678  2137.833333  403.852655   \n",
       "9                  0.523333                0.088468  2227.333333  542.415216   \n",
       "6                  0.491667                0.042622  2365.666667  268.500776   \n",
       "13                 0.465000                0.106724  2487.666667  563.395657   \n",
       "\n",
       "           MAE        R2  Price_Money  Mean_Price_Money  Std_Price_Money  \\\n",
       "0    72.594094  0.211413        40.45              6.74            13.54   \n",
       "7    73.115933  0.200557        13.96              2.33            10.60   \n",
       "4    71.819449  0.216850        13.96              2.33            10.60   \n",
       "3    73.820577  0.169581       -12.00             -2.00             0.00   \n",
       "11   72.173631  0.204637       -12.00             -2.00             0.00   \n",
       "2    99.665262 -0.519691       -12.00             -2.00             0.00   \n",
       "10   80.895114  0.015363       -12.00             -2.00             0.00   \n",
       "5    79.589731  0.048406       -12.00             -2.00             0.00   \n",
       "8    89.476773 -0.260619       -12.00             -2.00             0.00   \n",
       "12   78.254279  0.058488       -12.00             -2.00             0.00   \n",
       "1    89.734311 -0.253249       -12.00             -2.00             0.00   \n",
       "9   100.990465 -0.537225       -12.00             -2.00             0.00   \n",
       "6    84.979625 -0.114571       -12.00             -2.00             0.00   \n",
       "13   84.419723 -0.107398       -12.00             -2.00             0.00   \n",
       "\n",
       "    Count_Price_Won  \n",
       "0               2.0  \n",
       "7               1.0  \n",
       "4               1.0  \n",
       "3               0.0  \n",
       "11              0.0  \n",
       "2               0.0  \n",
       "10              0.0  \n",
       "5               0.0  \n",
       "8               0.0  \n",
       "12              0.0  \n",
       "1               0.0  \n",
       "9               0.0  \n",
       "6               0.0  \n",
       "13              0.0  "
      ]
     },
     "metadata": {},
     "execution_count": 373
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning for Linear Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "source": [
    "# model = LinearRegression()\n",
    "# parameters = {'fit_intercept':[True,False], 'normalize':[True,False]}\n",
    "# grid = GridSearchCV(model,parameters, cv=StratifiedKFold(shuffle=True, n_splits=5))\n",
    "\n",
    "# df_train = df[df['matchday'] <= 28]\n",
    "# df_test = df[df['matchday'] > 28]\n",
    "\n",
    "# # drop irrelevant features\n",
    "# df_train = df_train.drop(['name', 'matchday'], axis=1)\n",
    "\n",
    "# # split test data into feature and label\n",
    "# X_train = df_train.drop(['final_score'], axis='columns')\n",
    "# y_train = df_train['final_score']\n",
    "\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(grid.best_score_) # 0.23431358547187112\n",
    "# print(grid.best_params_) # {'fit_intercept': False, 'normalize': True} --> default Linear Regression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning for Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "source": [
    "# # Create RandomForestRegressor\n",
    "# rf = RandomForestRegressor()\n",
    "\n",
    "# # Load Data\n",
    "# df_train = df[df['matchday'] <= 28]\n",
    "# df_test = df[df['matchday'] > 28]\n",
    "\n",
    "# # drop irrelevant features\n",
    "# df_train = df_train.drop(['name', 'matchday'], axis=1)\n",
    "\n",
    "# # split test data into feature and label\n",
    "# X_train = df_train.drop(['final_score'], axis='columns')\n",
    "# y_train = df_train['final_score']\n",
    "\n",
    "\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 1, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv=StratifiedKFold(shuffle=True, n_splits=5), verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# rf_random.fit(X_train, y_train)\n",
    "\n",
    "# print(rf_random.best_score_) # 0.25267645010175976\n",
    "# print(rf_random.best_params_) # {'n_estimators': 1555, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True} "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "source": [
    "# param_grid = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [8, 9, 10, 11, 12],\n",
    "#     'max_features': ['sqrt'],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [2, 3, 4],\n",
    "#     'n_estimators': [1550, 1575, 1600, 1625, 1650]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv=StratifiedKFold(shuffle=True, n_splits=5), n_jobs = -1, verbose=2)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_score_) # 0.25773000067499996\n",
    "# print(grid_search.best_params_) # {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1625}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistical Tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cohens d and p-value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "source": [
    "treatment_row = df_model_accuracies.loc[(df_model_accuracies['design'] == 'treatment') & (df_model_accuracies['model'] == models[0])]\n",
    "baseline_row = df_model_accuracies.loc[(df_model_accuracies['design'] == 'baseline') & (df_model_accuracies['model'] == models[0])]\n",
    "\n",
    "differences_treatment = treatment_row['differences_from_best_lineup'].iloc[0]\n",
    "differences_baseline = baseline_row['differences_from_best_lineup'].iloc[0]\n",
    "\n",
    "rp.ttest(group1= differences_treatment, group1_name= \"differences_treatment\", group2= differences_baseline, group2_name= \"differences_baseline\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(                Variable     N         Mean          SD          SE  \\\n",
       " 0  differences_treatment   6.0  1483.666667  442.249100  180.547439   \n",
       " 1   differences_baseline   6.0  1671.666667  365.769691  149.324851   \n",
       " 2               combined  12.0  1577.666667  399.191304  115.236603   \n",
       " \n",
       "      95% Conf.     Interval  \n",
       " 0  1019.554699  1947.778634  \n",
       " 1  1287.814917  2055.518416  \n",
       " 2  1324.032613  1831.300720  ,\n",
       "                                   Independent t-test   results\n",
       " 0  Difference (differences_treatment - difference... -188.0000\n",
       " 1                              Degrees of freedom =    10.0000\n",
       " 2                                               t =    -0.8024\n",
       " 3                           Two side test p value =     0.4410\n",
       " 4                          Difference < 0 p value =     0.2205\n",
       " 5                          Difference > 0 p value =     0.7795\n",
       " 6                                       Cohen's d =    -0.4633\n",
       " 7                                       Hedge's g =    -0.4276\n",
       " 8                                   Glass's delta =    -0.4251\n",
       " 9                                     Pearson's r =     0.2459)"
      ]
     },
     "metadata": {},
     "execution_count": 377
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74907149d8cf8355762064ff20aca90cf6505446beaf5da5d3df333eff494a69"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}